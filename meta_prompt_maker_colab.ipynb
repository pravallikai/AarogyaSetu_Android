{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNorT8IEZQUd1m/33EyrrsW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pravallikai/AarogyaSetu_Android/blob/master/meta_prompt_maker_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gvC09Ccf29yN"
      },
      "outputs": [],
      "source": [
        "!mkdir meta_prompt_maker\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd meta_prompt_maker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7NDnVgE3EGo",
        "outputId": "6ae23b5b-7497-4b78-9acd-b6bafd668d03"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/meta_prompt_maker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir app"
      ],
      "metadata": {
        "id": "XtQ_qPWd3F3p"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir app/templates"
      ],
      "metadata": {
        "id": "BNSTgnay3JSI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "# FastAPI is the web framework\n",
        "fastapi==0.115.6\n",
        "\n",
        "# Uvicorn runs the FastAPI server\n",
        "uvicorn[standard]==0.34.0\n",
        "\n",
        "# HTTP client for APIs\n",
        "httpx==0.28.1\n",
        "\n",
        "# Loads environment variables safely\n",
        "python-dotenv==1.0.1\n",
        "\n",
        "# HTML template engine\n",
        "jinja2==3.1.4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3UhOU5Q3M1d",
        "outputId": "0e5eed95-8538-4498-82bd-a74bf76ddd60"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile README.md\n",
        "# Meta Prompt Maker\n",
        "\n",
        "Paste raw text and get a world-class, structured prompt.\n",
        "\n",
        "## Tech\n",
        "- FastAPI\n",
        "- NVIDIA API (primary)\n",
        "- OpenRouter API (fallback)\n",
        "\n",
        "## Run locally\n",
        "uvicorn app.main:app --reload\n",
        "\n",
        "## Deploy\n",
        "Ready for Render\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t77lvQX-3Orl",
        "outputId": "fbee90bf-3a44-4785-8501-62bbf41f4655"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app/prompt_builder.py\n",
        "# This function builds a clean, structured prompt from raw user text\n",
        "def build_structured_prompt(user_text: str) -> str:\n",
        "    # Remove extra spaces from the user input\n",
        "    cleaned_text = user_text.strip()\n",
        "\n",
        "    # Create the structured prompt using a formatted multi-line string\n",
        "    structured_prompt = f\"\"\"\n",
        "---\n",
        "## Task Definition\n",
        "You are an expert prompt engineer.\n",
        "Your task is to convert the user's raw input into a clear, high-quality prompt\n",
        "that another powerful AI model can execute accurately.\n",
        "\n",
        "## Context\n",
        "- Original user input:\n",
        "  \"{cleaned_text}\"\n",
        "\n",
        "- Assumptions:\n",
        "  - If details are missing, clearly state reasonable assumptions.\n",
        "  - Do not invent facts.\n",
        "  - Ask clarification questions only if absolutely required.\n",
        "\n",
        "- Style requirements:\n",
        "  - Clear\n",
        "  - Structured\n",
        "  - Professional\n",
        "  - Easy to understand\n",
        "\n",
        "## References\n",
        "- If the task involves writing (email, report, post), include a short example format.\n",
        "- If the task involves data or files, ask the user to provide them.\n",
        "- If the task involves reasoning, outline logical steps.\n",
        "\n",
        "## Evaluation Criteria\n",
        "- The output must fully match the user's intent.\n",
        "- The instructions must be unambiguous.\n",
        "- The output must be ready to use with minimal edits.\n",
        "\n",
        "## Iteration & Refinement\n",
        "- If the user wants changes, regenerate with:\n",
        "  - Different tone\n",
        "  - Different length\n",
        "  - More or less detail\n",
        "- Always improve clarity before adding complexity.\n",
        "---\n",
        "\"\"\"\n",
        "\n",
        "    # Return the final structured prompt\n",
        "    return structured_prompt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBmnRSSm3dzA",
        "outputId": "0ab42315-4fe6-4f30-90f8-60022fe3fb19"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app/prompt_builder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app/llm_clients.py\n",
        "# Import httpx to make HTTP requests to AI APIs\n",
        "import httpx\n",
        "\n",
        "# Import os to read environment variables (API keys)\n",
        "import os\n",
        "\n",
        "# This function sends the prompt to NVIDIA API\n",
        "async def call_nvidia(prompt: str) -> str:\n",
        "    # Get NVIDIA API key from environment variables\n",
        "    nvidia_api_key = os.getenv(\"NVIDIA_API_KEY\")\n",
        "\n",
        "    # If NVIDIA key is missing, stop and raise an error\n",
        "    if not nvidia_api_key:\n",
        "        raise RuntimeError(\"NVIDIA API key not found\")\n",
        "\n",
        "    # Define NVIDIA API endpoint (placeholder – user fills real endpoint)\n",
        "    url = \"https://api.nvidia.com/v1/chat/completions\"\n",
        "\n",
        "    # Prepare headers needed for authorization\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {nvidia_api_key}\",  # Proves who we are\n",
        "        \"Content-Type\": \"application/json\"             # We send JSON data\n",
        "    }\n",
        "\n",
        "    # Prepare request body for the AI model\n",
        "    payload = {\n",
        "        \"model\": \"nvidia-model-name\",                   # User sets model name\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}         # User prompt\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Send request to NVIDIA API\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        response = await client.post(url, headers=headers, json=payload)\n",
        "\n",
        "    # If NVIDIA API fails, raise an error\n",
        "    if response.status_code != 200:\n",
        "        raise RuntimeError(\"NVIDIA API request failed\")\n",
        "\n",
        "    # Convert response to JSON\n",
        "    data = response.json()\n",
        "\n",
        "    # Return the generated text from NVIDIA response\n",
        "    return data[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "\n",
        "# This function sends the prompt to OpenRouter API (fallback)\n",
        "async def call_openrouter(prompt: str) -> str:\n",
        "    # Get OpenRouter API key from environment variables\n",
        "    openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "\n",
        "    # If OpenRouter key is missing, stop and raise an error\n",
        "    if not openrouter_api_key:\n",
        "        raise RuntimeError(\"OpenRouter API key not found\")\n",
        "\n",
        "    # Define OpenRouter API endpoint\n",
        "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "\n",
        "    # Prepare headers for OpenRouter authentication\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {openrouter_api_key}\", # Proves who we are\n",
        "        \"Content-Type\": \"application/json\"                # JSON format\n",
        "    }\n",
        "\n",
        "    # Prepare request body\n",
        "    payload = {\n",
        "        \"model\": \"openrouter/model-name\",                 # User chooses model\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}           # User prompt\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Send request to OpenRouter\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        response = await client.post(url, headers=headers, json=payload)\n",
        "\n",
        "    # If OpenRouter API fails, raise an error\n",
        "    if response.status_code != 200:\n",
        "        raise RuntimeError(\"OpenRouter API request failed\")\n",
        "\n",
        "    # Convert response to JSON\n",
        "    data = response.json()\n",
        "\n",
        "    # Return the generated text from OpenRouter response\n",
        "    return data[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "\n",
        "# This function decides which API to use\n",
        "async def generate_with_fallback(prompt: str) -> tuple[str, str]:\n",
        "    # First, try NVIDIA API\n",
        "    try:\n",
        "        result = await call_nvidia(prompt)\n",
        "        return result, \"NVIDIA\"\n",
        "    except Exception:\n",
        "        pass  # If NVIDIA fails, move to OpenRouter\n",
        "\n",
        "    # If NVIDIA fails, try OpenRouter\n",
        "    try:\n",
        "        result = await call_openrouter(prompt)\n",
        "        return result, \"OpenRouter\"\n",
        "    except Exception:\n",
        "        pass  # If OpenRouter also fails, continue\n",
        "\n",
        "    # If both APIs fail, return an error message\n",
        "    return \"All APIs failed. Please check API keys or limits.\", \"None\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYk0jJKr3vCJ",
        "outputId": "f5d91c8f-a293-4ac6-daa6-59e162e2f152"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app/llm_clients.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app/main.py\n",
        "# Import FastAPI to create the web application\n",
        "from fastapi import FastAPI, Request\n",
        "\n",
        "# Import HTMLResponse so we can return HTML pages\n",
        "from fastapi.responses import HTMLResponse, JSONResponse\n",
        "\n",
        "# Import Jinja2Templates to render HTML templates\n",
        "from fastapi.templating import Jinja2Templates\n",
        "\n",
        "# Import StaticFiles to serve static files like CSS (if needed later)\n",
        "from fastapi.staticfiles import StaticFiles\n",
        "\n",
        "# Import our prompt builder logic\n",
        "from app.prompt_builder import build_structured_prompt\n",
        "\n",
        "# Import our API fallback logic (NVIDIA → OpenRouter)\n",
        "from app.llm_clients import generate_with_fallback\n",
        "\n",
        "# Create the FastAPI application\n",
        "app = FastAPI(title=\"Meta Prompt Maker\")\n",
        "\n",
        "# Tell FastAPI where HTML templates are stored\n",
        "templates = Jinja2Templates(directory=\"app/templates\")\n",
        "\n",
        "# (Optional) Mount static folder for future CSS/JS\n",
        "app.mount(\"/static\", StaticFiles(directory=\"app\"), name=\"static\")\n",
        "\n",
        "\n",
        "# This route shows the main web page\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def home(request: Request):\n",
        "    # Render index.html and pass request object\n",
        "    return templates.TemplateResponse(\n",
        "        \"index.html\",\n",
        "        {\"request\": request}\n",
        "    )\n",
        "\n",
        "\n",
        "# This API route generates a structured prompt\n",
        "@app.post(\"/api/generate\")\n",
        "async def generate_prompt(payload: dict):\n",
        "    # Extract text sent by the user\n",
        "    user_text = payload.get(\"text\", \"\").strip()\n",
        "\n",
        "    # If user did not send text, return an error\n",
        "    if not user_text:\n",
        "        return JSONResponse(\n",
        "            {\"error\": \"Please enter some text.\"},\n",
        "            status_code=400\n",
        "        )\n",
        "\n",
        "    # Build the structured prompt locally\n",
        "    structured_prompt = build_structured_prompt(user_text)\n",
        "\n",
        "    # Send prompt to NVIDIA → OpenRouter fallback\n",
        "    result, provider = await generate_with_fallback(structured_prompt)\n",
        "\n",
        "    # Return the final result to the UI\n",
        "    return {\n",
        "        \"provider\": provider,\n",
        "        \"prompt\": result\n",
        "    }\n",
        "\n",
        "\n",
        "# This API route regenerates the prompt\n",
        "@app.post(\"/api/regenerate\")\n",
        "async def regenerate_prompt(payload: dict):\n",
        "    # Reuse the same generation logic\n",
        "    return await generate_prompt(payload)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsFZeEZJ36sM",
        "outputId": "ea06a77e-f21a-4e8e-8eda-e5ace96c02b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app/templates/index.html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <!-- Set character encoding -->\n",
        "    <meta charset=\"UTF-8\">\n",
        "\n",
        "    <!-- Page title shown in browser tab -->\n",
        "    <title>Meta Prompt Maker</title>\n",
        "\n",
        "    <!-- Make page responsive on all devices -->\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
        "\n",
        "    <!-- Simple styling for clean UI -->\n",
        "    <style>\n",
        "        body {\n",
        "            font-family: Arial, sans-serif;   /* Easy-to-read font */\n",
        "            max-width: 900px;                 /* Limit width */\n",
        "            margin: 30px auto;                /* Center page */\n",
        "            padding: 10px;\n",
        "        }\n",
        "        textarea {\n",
        "            width: 100%;                      /* Full width */\n",
        "            height: 180px;                    /* Big input box */\n",
        "            padding: 10px;\n",
        "        }\n",
        "        button {\n",
        "            padding: 10px 15px;               /* Button size */\n",
        "            margin-top: 10px;\n",
        "            cursor: pointer;\n",
        "        }\n",
        "        pre {\n",
        "            background: #f5f5f5;              /* Light background */\n",
        "            padding: 15px;\n",
        "            white-space: pre-wrap;            /* Wrap text */\n",
        "            border-radius: 8px;\n",
        "            margin-top: 15px;\n",
        "        }\n",
        "        .provider {\n",
        "            margin-top: 10px;\n",
        "            font-size: 14px;\n",
        "            color: #555;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "\n",
        "    <!-- App heading -->\n",
        "    <h2>Meta Prompt Maker</h2>\n",
        "\n",
        "    <!-- Text area for user input -->\n",
        "    <textarea id=\"inputText\" placeholder=\"Paste your raw text here...\"></textarea>\n",
        "\n",
        "    <!-- Generate button -->\n",
        "    <button onclick=\"generatePrompt()\">Generate</button>\n",
        "\n",
        "    <!-- Regenerate button -->\n",
        "    <button onclick=\"regeneratePrompt()\">Regenerate</button>\n",
        "\n",
        "    <!-- Shows which API was used -->\n",
        "    <div class=\"provider\" id=\"providerInfo\"></div>\n",
        "\n",
        "    <!-- Output area -->\n",
        "    <pre id=\"outputArea\">Your structured prompt will appear here.</pre>\n",
        "\n",
        "    <!-- JavaScript logic -->\n",
        "    <script>\n",
        "        // Call backend API to generate prompt\n",
        "        async function generatePrompt() {\n",
        "            const text = document.getElementById(\"inputText\").value;\n",
        "\n",
        "            const response = await fetch(\"/api/generate\", {\n",
        "                method: \"POST\",\n",
        "                headers: { \"Content-Type\": \"application/json\" },\n",
        "                body: JSON.stringify({ text: text })\n",
        "            });\n",
        "\n",
        "            const data = await response.json();\n",
        "\n",
        "            if (data.error) {\n",
        "                alert(data.error);\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            document.getElementById(\"providerInfo\").innerText =\n",
        "                \"Generated using: \" + data.provider;\n",
        "\n",
        "            document.getElementById(\"outputArea\").innerText =\n",
        "                data.prompt;\n",
        "        }\n",
        "\n",
        "        // Regenerate simply calls generate again\n",
        "        async function regeneratePrompt() {\n",
        "            await generatePrompt();\n",
        "        }\n",
        "    </script>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnqSzwZ_4Gz0",
        "outputId": "35fa7052-cd39-4c4d-b693-477233cb5f75"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app/templates/index.html\n"
          ]
        }
      ]
    }
  ]
}